"""
Core data models for the Automotive Media Engine.

These Pydantic models define the structure of content throughout the pipeline,
ensuring type safety and validation at each stage.
"""

from datetime import datetime
from enum import Enum
from typing import Optional, List
from pydantic import BaseModel, Field, field_validator


class Platform(str, Enum):
    """Supported video platforms with specific format requirements."""
    LINKEDIN = "linkedin"
    TIKTOK = "tiktok"
    INSTAGRAM = "instagram"
    YOUTUBE = "youtube"


class AudienceLevel(str, Enum):
    """Target audience technical sophistication."""
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"


class StyleArchetype(str, Enum):
    """Visual and narrative archetypes for video generation."""
    TECHNICAL = "technical"           # ByCloud AI style (Blueprints, Grids)
    STORYTELLING = "storytelling"     # VidaSegunRichie style (Focus on hooks, retention)
    DOCUMENTARY = "documentary"       # Veritasium style (Explanatory, pedagogical)
    MINIMALIST = "minimalist"         # Ecomonos style (Clean, typographic)


class QualityPreset(str, Enum):
    """Video encoding quality presets."""
    ULTRA = "ultra"      # CRF 18, slow - archival quality
    STANDARD = "standard"  # CRF 23, medium - social media
    FAST = "fast"        # CRF 28, fast - testing


class ContentBrief(BaseModel):
    """
    Input specification for video generation.
    Created manually or by content research MCP server.
    """
    topic: str = Field(..., description="Main topic/title of the video")
    key_points: List[str] = Field(..., min_length=1, max_length=5,
                                   description="3-5 key technical points to cover")
    target_duration: int = Field(60, ge=15, le=180,
                                  description="Target duration in seconds")
    platform: Platform = Field(Platform.LINKEDIN,
                                description="Target platform for formatting")
    audience_level: AudienceLevel = Field(AudienceLevel.INTERMEDIATE,
                                           description="Target audience expertise")
    style_archetype: StyleArchetype = Field(StyleArchetype.TECHNICAL,
                                             description="Visual and narrative style archetype")
    visual_references: Optional[List[str]] = Field(None,
                                                    description="Suggested visuals/diagrams")
    call_to_action: Optional[str] = Field(None,
                                          description="What viewers should do next")
    
    @field_validator('key_points')
    @classmethod
    def validate_key_points(cls, v):
        """Ensure key points are substantive."""
        if any(len(point.strip()) < 10 for point in v):
            raise ValueError("Each key point must be at least 10 characters")
        return v


class Scene(BaseModel):
    """
    Individual segment of the video with timing and content.
    """
    scene_number: int = Field(..., ge=1)
    narration_text: str = Field(..., min_length=10)
    start_time: float = Field(..., ge=0.0, description="Start time in seconds")
    duration: float = Field(..., gt=0.0, description="Scene duration in seconds")
    visual_type: str = Field(..., description="Type of visual: diagram, text, stock_video")
    visual_config: dict = Field(default_factory=dict,
                                description="Configuration for visual generation")
    
    @property
    def end_time(self) -> float:
        """Calculate end time of scene."""
        return self.start_time + self.duration


class VideoScript(BaseModel):
    """
    Structured narration with timing information.
    Generated by script_engine from ContentBrief.
    """
    brief: ContentBrief
    scenes: List[Scene] = Field(..., min_length=1)
    total_duration: float = Field(..., gt=0.0)
    script_text: str = Field(..., description="Full narration text")
    generated_at: datetime = Field(default_factory=datetime.now)
    usage_metadata: Optional[dict] = Field(None, description="LLM token usage")
    
    @field_validator('scenes')
    @classmethod
    def validate_scene_timing(cls, v):
        """Ensure scenes don't overlap and are chronologically ordered."""
        for i in range(len(v) - 1):
            current_end = v[i].end_time
            next_start = v[i + 1].start_time
            if current_end > next_start:
                raise ValueError(f"Scene {i+1} overlaps with scene {i+2}")
        return v
    
    @property
    def word_count(self) -> int:
        """Calculate total word count for pacing analysis."""
        return len(self.script_text.split())
    
    @property
    def words_per_minute(self) -> float:
        """Calculate speaking pace."""
        return (self.word_count / self.total_duration) * 60


class VideoConfig(BaseModel):
    """
    Complete video project configuration.
    """
    project_name: str = Field(..., min_length=1, max_length=100)
    script: VideoScript
    quality: QualityPreset = Field(QualityPreset.STANDARD)
    voice_id: str = Field("adam", description="ElevenLabs voice model")
    output_path: Optional[str] = Field(None)
    created_at: datetime = Field(default_factory=datetime.now)
    
    @property
    def platform_specs(self) -> dict:
        """Get platform-specific encoding specs."""
        specs = {
            Platform.LINKEDIN: {
                "resolution": (1080, 1080),
                "aspect_ratio": "1:1",
                "fps": 30,
                "max_duration": 600,
            },
            Platform.TIKTOK: {
                "resolution": (1080, 1920),
                "aspect_ratio": "9:16",
                "fps": 30,
                "max_duration": 180,
            },
            Platform.INSTAGRAM: {
                "resolution": (1080, 1920),
                "aspect_ratio": "9:16",
                "fps": 30,
                "max_duration": 90,
            },
            Platform.YOUTUBE: {
                "resolution": (1080, 1920),
                "aspect_ratio": "9:16",
                "fps": 30,
                "max_duration": 60,
            },
        }
        return specs[self.script.brief.platform]


class GenerationResult(BaseModel):
    """
    Result of video generation process with metadata.
    """
    success: bool
    video_path: Optional[str] = None
    thumbnail_path: Optional[str] = None
    duration: float
    file_size_mb: Optional[float] = None
    generation_time_seconds: float
    error_message: Optional[str] = None
    metadata: dict = Field(default_factory=dict)
